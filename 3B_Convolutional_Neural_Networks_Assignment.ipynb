{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Assignment: Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Duke Community Standard](http://integrity.duke.edu/standard.html): By typing your name below, you are certifying that you have adhered to the Duke Community Standard in completing this assignment.**\n",
    "\n",
    "Name: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network\n",
    "\n",
    "Adapt the CNN example for MNIST digit classfication from Notebook 3A. \n",
    "Feel free to play around with the model architecture and see how the training time/performance changes, but to begin, try the following:\n",
    "\n",
    "Image ->  \n",
    "convolution (32 3x3 filters) -> nonlinearity (ReLU) ->  \n",
    "convolution (32 3x3 filters) -> nonlinearity (ReLU) -> (2x2 max pool) ->  \n",
    "convolution (64 3x3 filters) -> nonlinearity (ReLU) ->  \n",
    "convolution (64 3x3 filters) -> nonlinearity (ReLU) -> (2x2 max pool) -> flatten ->\n",
    "fully connected (256 hidden units) -> nonlinearity (ReLU) ->  \n",
    "fully connected (10 hidden units) -> softmax \n",
    "\n",
    "Note: The CNN model might take a while to train. Depending on your machine, you might expect this to take up to half an hour. If you see your validation performance start to plateau, you can kill the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "original: $5 \\times 5$ convolution -> $2 \\times 2$ max pool -> $5 \\times 5$ convolution -> $2 \\times 2$ max pool -> fully connected to $\\mathbb R^{256}$ -> fully connected to $\\mathbb R^{10}$ (prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a639ea734f3e41629847e2714caaf73f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90fe2717f4f244668165df1b342630e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b9fa057c7244f56ab2a55ee45d3468c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "523b5458f21842e4b64b87f7f815bf35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a521e248cac242a1a1cc9962e24a8fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9907000064849854\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE ###\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "class MNIST_CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1_1 = nn.Conv2d(1, 32, kernel_size=3, padding=1) # 1 input channels for RGB images, 32 output channels\n",
    "        self.conv1_2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.conv2_1 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv2_2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Flatten -> fully connected layers\n",
    "        # The input to the first fully connected layer will be 64 * 7 * 7 = 3136 features\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 256) # 64 channels * 7 height * 7 width, NMIST images are standardly 28x28 pixels in grayscale\n",
    "        self.fc2 = nn.Linear(256, 10) \n",
    "\n",
    "        # self.conv1 = nn.Conv2d(1, 32, kernel_size=5, padding=2)\n",
    "        # self.conv2 = nn.Conv2d(32, 64, kernel_size=5, padding=2)\n",
    "        # self.fc1 = nn.Linear(7*7*64, 256)\n",
    "        # self.fc2 = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # First Block\n",
    "        x = F.relu(self.conv1_1(x))\n",
    "        x = F.relu(self.conv1_2(x))\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "\n",
    "        # Second Block\n",
    "        x = F.relu(self.conv2_1(x))\n",
    "        x = F.relu(self.conv2_2(x))\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "\n",
    "        # Flatten for fully connected layers\n",
    "        # x.size(0) gets the batch size, -1 infers the remaining dimensions\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        # Fully Connected Layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x) # No softmax here; CrossEntropyLoss handles it internally\n",
    "\n",
    "        return x\n",
    "        \n",
    "        # conv layer 1\n",
    "        # x = self.conv1(x)\n",
    "        # x = F.relu(x)\n",
    "        # x = F.max_pool2d(x, kernel_size=2)\n",
    "        \n",
    "        # # conv layer 2\n",
    "        # x = self.conv2(x)\n",
    "        # x = F.relu(x)\n",
    "        # x = F.max_pool2d(x, kernel_size=2)\n",
    "        \n",
    "        # # fc layer 1\n",
    "        # x = x.view(-1, 7*7*64)\n",
    "        # x = self.fc1(x)\n",
    "        # x = F.relu(x)\n",
    "        \n",
    "        # # fc layer 2\n",
    "        # x = self.fc2(x)\n",
    "        # return x     \n",
    "\n",
    "# Load the data\n",
    "mnist_train = datasets.MNIST(root=\"./datasets\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "mnist_test = datasets.MNIST(root=\"./datasets\", train=False, transform=transforms.ToTensor(), download=True)\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=100, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=100, shuffle=False)\n",
    "\n",
    "## Training\n",
    "# Instantiate model  \n",
    "model = MNIST_CNN()  # <---- change here\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # <---- change here\n",
    "\n",
    "# Iterate through train set minibatchs \n",
    "for epoch in trange(3):  # <---- change here\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        # Zero out the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        x = images  # <---- change here \n",
    "        y = model(x)\n",
    "        loss = criterion(y, labels)\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "## Testing\n",
    "correct = 0\n",
    "total = len(mnist_test)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Iterate through test set minibatchs \n",
    "    for images, labels in tqdm(test_loader):\n",
    "        # Forward pass\n",
    "        x = images  # <---- change here \n",
    "        y = model(x)\n",
    "\n",
    "        predictions = torch.argmax(y, dim=1)\n",
    "        correct += torch.sum((predictions == labels).float())\n",
    "\n",
    "print('Test accuracy: {}'.format(correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short answer\n",
    "\n",
    "1\\. How does the CNN compare in accuracy with yesterday's logistic regression and MLP models? How about training time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Higher accuracy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. How many trainable parameters are there in the CNN you built for this assignment?\n",
    "\n",
    "*Note: The total of trainable parameters counts each element in a tensor. For example, a weight matrix that is 10x5 has 50 trainable parameters.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Summing up the parameters from each layer:`\n",
    "\n",
    "`conv1_1: 320`\n",
    "\n",
    "`conv1_2: 9,248`\n",
    "\n",
    "`conv2_1: 18,496`\n",
    "\n",
    "`conv2_2: 36,928`\n",
    "\n",
    "`fc1: 803,072`\n",
    "\n",
    "`fc2: 2,570`\n",
    "\n",
    "`Total = 320 + 9248 + 18496 + 36928 + 803072 + 2570 = 870,634`\n",
    "\n",
    "`The MNIST_CNN model you built for this assignment has 870,634 trainable parameters.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. When would you use a CNN versus a logistic regression model or an MLP?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Use a Convolutional Neural Network (CNN) primarily for data with a grid-like topology, such as images, videos, or even 1D time series, because their architecture (local connectivity, parameter sharing, and pooling) is inherently designed to capture spatial hierarchies and local patterns effectively, leading to robust feature extraction and translation invariance. `\n",
    "\n",
    "`In contrast, Logistic Regression is suitable for simple, linearly separable tabular data where interpretability is crucial and non-linear relationships are minimal. `\n",
    "\n",
    "`A Multilayer Perceptron (MLP) serves as a more general-purpose neural network for complex, non-linear tabular data, but it typically struggles with raw image data due to the loss of spatial information upon flattening and an explosion in parameters compared to CNNs.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
